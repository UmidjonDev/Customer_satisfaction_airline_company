{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zlfg_OQeOTey"
      },
      "source": [
        "### This jupyter notebook contains training process of machine learning models with the help of tensorflow library in the given problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-ujCXuxOTe0"
      },
      "source": [
        "### **Author : Umidjon Sattorov student at Mohirdev platform**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding google drive to colab environment.\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SV-Ae-5EOgXT",
        "outputId": "564c0672-4e2d-4790-f5ec-2e90aea46a71"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dill"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZvfhoiMPUHF",
        "outputId": "15ae4a74-66ca-4f69-ca1a-4da99cb6658e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dill\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dill\n",
            "Successfully installed dill-0.3.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "52P4pk9fOTe1"
      },
      "outputs": [],
      "source": [
        "#Importing all necessary libraries and modules\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "#Data processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#Preprocessing and feature engineering\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Modelling\n",
        "import tensorflow as tf\n",
        "import fastai\n",
        "from fastai.tabular.all import *\n",
        "\n",
        "#Metrics\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "#Saving machine learning model into pickle format\n",
        "import dill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "RIAPWqypOTe2",
        "outputId": "319aee67-f90d-492b-e495-d1c0cabf511e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  Gender      Customer Type  Age   Type of Travel     Class  \\\n",
              "0   1    Male  disloyal Customer   33  Business travel       Eco   \n",
              "1   2  Female     Loyal Customer   49  Business travel  Business   \n",
              "2   3  Female     Loyal Customer   43  Business travel       Eco   \n",
              "3   4  Female     Loyal Customer   27  Business travel  Business   \n",
              "4   5    Male     Loyal Customer   11  Personal Travel       Eco   \n",
              "\n",
              "   Flight Distance  Inflight wifi service  Departure/Arrival time convenient  \\\n",
              "0              571                      2                                  3   \n",
              "1             1431                      4                                  1   \n",
              "2              867                      1                                  4   \n",
              "3             1550                      3                                  3   \n",
              "4              526                      3                                  4   \n",
              "\n",
              "   Ease of Online booking  ...  Inflight entertainment  On-board service  \\\n",
              "0                       2  ...                       4                 3   \n",
              "1                       4  ...                       5                 5   \n",
              "2                       4  ...                       1                 1   \n",
              "3                       3  ...                       2                 4   \n",
              "4                       3  ...                       4                 5   \n",
              "\n",
              "   Leg room service  Baggage handling  Checkin service  Inflight service  \\\n",
              "0                 1                 3                4                 3   \n",
              "1                 5                 5                3                 5   \n",
              "2                 1                 1                1                 1   \n",
              "3                 4                 5                5                 4   \n",
              "4                 2                 5                3                 5   \n",
              "\n",
              "   Cleanliness  Departure Delay in Minutes  Arrival Delay in Minutes  \\\n",
              "0            4                          10                       3.0   \n",
              "1            3                           0                       0.0   \n",
              "2            2                           0                      18.0   \n",
              "3            2                           0                       0.0   \n",
              "4            4                           0                      10.0   \n",
              "\n",
              "   satisfaction  \n",
              "0             0  \n",
              "1             1  \n",
              "2             0  \n",
              "3             1  \n",
              "4             0  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e26aeabc-9e08-4cf1-b8bf-16b32df2e085\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Customer Type</th>\n",
              "      <th>Age</th>\n",
              "      <th>Type of Travel</th>\n",
              "      <th>Class</th>\n",
              "      <th>Flight Distance</th>\n",
              "      <th>Inflight wifi service</th>\n",
              "      <th>Departure/Arrival time convenient</th>\n",
              "      <th>Ease of Online booking</th>\n",
              "      <th>...</th>\n",
              "      <th>Inflight entertainment</th>\n",
              "      <th>On-board service</th>\n",
              "      <th>Leg room service</th>\n",
              "      <th>Baggage handling</th>\n",
              "      <th>Checkin service</th>\n",
              "      <th>Inflight service</th>\n",
              "      <th>Cleanliness</th>\n",
              "      <th>Departure Delay in Minutes</th>\n",
              "      <th>Arrival Delay in Minutes</th>\n",
              "      <th>satisfaction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Male</td>\n",
              "      <td>disloyal Customer</td>\n",
              "      <td>33</td>\n",
              "      <td>Business travel</td>\n",
              "      <td>Eco</td>\n",
              "      <td>571</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Female</td>\n",
              "      <td>Loyal Customer</td>\n",
              "      <td>49</td>\n",
              "      <td>Business travel</td>\n",
              "      <td>Business</td>\n",
              "      <td>1431</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Female</td>\n",
              "      <td>Loyal Customer</td>\n",
              "      <td>43</td>\n",
              "      <td>Business travel</td>\n",
              "      <td>Eco</td>\n",
              "      <td>867</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Female</td>\n",
              "      <td>Loyal Customer</td>\n",
              "      <td>27</td>\n",
              "      <td>Business travel</td>\n",
              "      <td>Business</td>\n",
              "      <td>1550</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Male</td>\n",
              "      <td>Loyal Customer</td>\n",
              "      <td>11</td>\n",
              "      <td>Personal Travel</td>\n",
              "      <td>Eco</td>\n",
              "      <td>526</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e26aeabc-9e08-4cf1-b8bf-16b32df2e085')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e26aeabc-9e08-4cf1-b8bf-16b32df2e085 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e26aeabc-9e08-4cf1-b8bf-16b32df2e085');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f8938e06-d7f7-44d0-b66e-95714f781314\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f8938e06-d7f7-44d0-b66e-95714f781314')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f8938e06-d7f7-44d0-b66e-95714f781314 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#Reading dataset into pandas dataframe\n",
        "df = pd.read_csv(filepath_or_buffer = '/content/drive/MyDrive/ml/data/imputed_train_dataset.csv', sep = ',')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping unneccesary columns from the dataset\n",
        "cols_left = ['Customer Type', 'Age', 'Type of Travel', 'Class', 'Flight Distance', 'Inflight wifi service', 'Ease of Online booking', 'Food and drink', 'Online boarding', 'Seat comfort', 'Inflight entertainment', 'On-board service', 'Leg room service', 'Baggage handling', 'Checkin service', 'Inflight service', 'Cleanliness', 'satisfaction']\n",
        "df = df[cols_left]\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "Oyaf5C5hzEAW",
        "outputId": "937bce88-caaa-4d67-e365-d8beaf214883"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Customer Type  Age   Type of Travel     Class  Flight Distance  \\\n",
              "0  disloyal Customer   33  Business travel       Eco              571   \n",
              "1     Loyal Customer   49  Business travel  Business             1431   \n",
              "2     Loyal Customer   43  Business travel       Eco              867   \n",
              "3     Loyal Customer   27  Business travel  Business             1550   \n",
              "4     Loyal Customer   11  Personal Travel       Eco              526   \n",
              "\n",
              "   Inflight wifi service  Ease of Online booking  Food and drink  \\\n",
              "0                      2                       2               4   \n",
              "1                      4                       4               3   \n",
              "2                      1                       4               4   \n",
              "3                      3                       3               2   \n",
              "4                      3                       3               4   \n",
              "\n",
              "   Online boarding  Seat comfort  Inflight entertainment  On-board service  \\\n",
              "0                2             4                       4                 3   \n",
              "1                5             4                       5                 5   \n",
              "2                4             3                       1                 1   \n",
              "3                2             2                       2                 4   \n",
              "4                3             4                       4                 5   \n",
              "\n",
              "   Leg room service  Baggage handling  Checkin service  Inflight service  \\\n",
              "0                 1                 3                4                 3   \n",
              "1                 5                 5                3                 5   \n",
              "2                 1                 1                1                 1   \n",
              "3                 4                 5                5                 4   \n",
              "4                 2                 5                3                 5   \n",
              "\n",
              "   Cleanliness  satisfaction  \n",
              "0            4             0  \n",
              "1            3             1  \n",
              "2            2             0  \n",
              "3            2             1  \n",
              "4            4             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b97848b8-6b15-4986-9833-a601913a2ccb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Customer Type</th>\n",
              "      <th>Age</th>\n",
              "      <th>Type of Travel</th>\n",
              "      <th>Class</th>\n",
              "      <th>Flight Distance</th>\n",
              "      <th>Inflight wifi service</th>\n",
              "      <th>Ease of Online booking</th>\n",
              "      <th>Food and drink</th>\n",
              "      <th>Online boarding</th>\n",
              "      <th>Seat comfort</th>\n",
              "      <th>Inflight entertainment</th>\n",
              "      <th>On-board service</th>\n",
              "      <th>Leg room service</th>\n",
              "      <th>Baggage handling</th>\n",
              "      <th>Checkin service</th>\n",
              "      <th>Inflight service</th>\n",
              "      <th>Cleanliness</th>\n",
              "      <th>satisfaction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>disloyal Customer</td>\n",
              "      <td>33</td>\n",
              "      <td>Business travel</td>\n",
              "      <td>Eco</td>\n",
              "      <td>571</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Loyal Customer</td>\n",
              "      <td>49</td>\n",
              "      <td>Business travel</td>\n",
              "      <td>Business</td>\n",
              "      <td>1431</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Loyal Customer</td>\n",
              "      <td>43</td>\n",
              "      <td>Business travel</td>\n",
              "      <td>Eco</td>\n",
              "      <td>867</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Loyal Customer</td>\n",
              "      <td>27</td>\n",
              "      <td>Business travel</td>\n",
              "      <td>Business</td>\n",
              "      <td>1550</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Loyal Customer</td>\n",
              "      <td>11</td>\n",
              "      <td>Personal Travel</td>\n",
              "      <td>Eco</td>\n",
              "      <td>526</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b97848b8-6b15-4986-9833-a601913a2ccb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b97848b8-6b15-4986-9833-a601913a2ccb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b97848b8-6b15-4986-9833-a601913a2ccb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8dc9ae72-e017-422a-b167-3b377c8104fe\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8dc9ae72-e017-422a-b167-3b377c8104fe')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8dc9ae72-e017-422a-b167-3b377c8104fe button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"Customer Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Loyal Customer\",\n          \"disloyal Customer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 7,\n        \"max\": 80,\n        \"num_unique_values\": 74,\n        \"samples\": [\n          11,\n          70\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type of Travel\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Personal Travel\",\n          \"Business travel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Eco\",\n          \"Business\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Flight Distance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1022,\n        \"min\": 31,\n        \"max\": 4983,\n        \"num_unique_values\": 2421,\n        \"samples\": [\n          628,\n          1548\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Inflight wifi service\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          2,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ease of Online booking\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          2,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Food and drink\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Online boarding\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          2,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Seat comfort\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Inflight entertainment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"On-board service\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Leg room service\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Baggage handling\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Checkin service\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Inflight service\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cleanliness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"satisfaction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CKbO5lCLOTe2",
        "outputId": "209c806f-2d5a-4baa-f19a-79151fc7d9c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Customer Type             0\n",
              "Age                       0\n",
              "Type of Travel            0\n",
              "Class                     0\n",
              "Flight Distance           0\n",
              "Inflight wifi service     0\n",
              "Ease of Online booking    0\n",
              "Food and drink            0\n",
              "Online boarding           0\n",
              "Seat comfort              0\n",
              "Inflight entertainment    0\n",
              "On-board service          0\n",
              "Leg room service          0\n",
              "Baggage handling          0\n",
              "Checkin service           0\n",
              "Inflight service          0\n",
              "Cleanliness               0\n",
              "satisfaction              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#Checking iff there is any empty values in the dataset\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zOQbH6jfOTe3"
      },
      "outputs": [],
      "source": [
        "#Dividing data into train and test datasets\n",
        "train_df, test_df = train_test_split(df, test_size = 0.2, random_state = 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.select_dtypes(include = ['int64', 'float64']).columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oZGA9LU0JmA",
        "outputId": "d84255e2-765b-4e19-91c7-02fcf3e2a4b8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Age', 'Flight Distance', 'Inflight wifi service',\n",
              "       'Ease of Online booking', 'Food and drink', 'Online boarding',\n",
              "       'Seat comfort', 'Inflight entertainment', 'On-board service',\n",
              "       'Leg room service', 'Baggage handling', 'Checkin service',\n",
              "       'Inflight service', 'Cleanliness', 'satisfaction'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z027ZqroOTe3"
      },
      "outputs": [],
      "source": [
        "#Creating training and test dataset for using with tensorflow algorithms\n",
        "CATEGORICAL_COLUMNS = train_df.select_dtypes(include = ['object']).columns\n",
        "NUMERIC_COLUMNS = ['Flight Distance', 'Inflight wifi service', 'Food and drink', 'Online boarding', 'Seat comfort', 'Inflight entertainment', 'On-board service', 'Leg room service', 'Baggage handling', 'Checkin service', 'Inflight service', 'Cleanliness']\n",
        "\n",
        "preprocessing_layers = []\n",
        "inputs = []\n",
        "\n",
        "# Creating preprocessing layers for categorical features\n",
        "for feature_name in CATEGORICAL_COLUMNS:\n",
        "    vocabulary = df[feature_name].unique()\n",
        "    cat_input = tf.keras.Input(shape = (1,), name = feature_name, dtype = tf.string)\n",
        "    cat_layer = tf.keras.layers.StringLookup(vocabulary = list(vocabulary))(cat_input)\n",
        "    cat_layer = tf.keras.layers.Lambda(lambda x: tf.cast(x, dtype = tf.float32))(cat_layer)\n",
        "    inputs.append(cat_input)\n",
        "\n",
        "# Creating preprocessing layers for numerical features\n",
        "for feature_name in NUMERIC_COLUMNS:\n",
        "    num_input = tf.keras.Input(shape = (1,), name = feature_name)\n",
        "    norm_layer = tf.keras.layers.Normalization()(num_input)\n",
        "    preprocessing_layers.append(norm_layer)\n",
        "    inputs.append(num_input)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenating preprocessing layers\n",
        "concatenated_inputs = tf.keras.layers.concatenate(preprocessing_layers)"
      ],
      "metadata": {
        "id": "FNXPPIWyHEvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUQbSB9mOTe3"
      },
      "source": [
        "### Modelling linear classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuGBBrdyOTe4"
      },
      "outputs": [],
      "source": [
        "# Build the model\n",
        "linear_model = tf.keras.layers.Dense(1, activation = 'sigmoid')(concatenated_inputs)\n",
        "model = tf.keras.Model(inputs = inputs, outputs = linear_model)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Making input function for model\n",
        "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
        "    dataframe = dataframe.copy()\n",
        "    labels = dataframe.pop('satisfaction')\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(buffer_size = len(dataframe))\n",
        "    ds = ds.batch(batch_size)\n",
        "    return ds\n",
        "\n",
        "batch_size = 32\n",
        "train_ds = df_to_dataset(train_df, batch_size = batch_size)\n",
        "test_ds = df_to_dataset(test_df, shuffle = False, batch_size = batch_size)"
      ],
      "metadata": {
        "id": "k6N8BUE8IkqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trainining model\n",
        "model.fit(train_ds, epochs = 100)\n",
        "\n",
        "# Evaluating the model\n",
        "eval_result = model.evaluate(test_ds)\n",
        "print(f\"Evaluation results: {eval_result}\")\n",
        "\n",
        "# Getting predictions and calculate ROC AUC score\n",
        "test_predictions = model.predict(test_ds)\n",
        "true_labels = list(test_df['satisfaction'])\n",
        "roc_auc = roc_auc_score(true_labels, test_predictions)\n",
        "print(f\"ROC AUC score: {roc_auc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W8fXezKJLjG",
        "outputId": "c87b228c-d033-4680-bee7-9248226af777"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 2s 2ms/step - loss: 193.1610 - accuracy: 0.5021 - auc: 0.5001\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 79.2515 - accuracy: 0.5006 - auc: 0.4995\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 7.1710 - accuracy: 0.5839 - auc: 0.5846\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 3.6418 - accuracy: 0.5916 - auc: 0.5873\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 2.0572 - accuracy: 0.5870 - auc: 0.5841\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.9998 - accuracy: 0.5817 - auc: 0.6089\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.8096 - accuracy: 0.5943 - auc: 0.6254\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.7864 - accuracy: 0.5984 - auc: 0.6336\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.7647 - accuracy: 0.6089 - auc: 0.6442\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.7335 - accuracy: 0.6195 - auc: 0.6572\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.7107 - accuracy: 0.6311 - auc: 0.6719\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.6860 - accuracy: 0.6390 - auc: 0.6857\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6781 - accuracy: 0.6510 - auc: 0.6928\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6520 - accuracy: 0.6620 - auc: 0.7105\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6387 - accuracy: 0.6666 - auc: 0.7213\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6361 - accuracy: 0.6724 - auc: 0.7222\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6245 - accuracy: 0.6829 - auc: 0.7330\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6040 - accuracy: 0.6957 - auc: 0.7525\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5986 - accuracy: 0.7040 - auc: 0.7599\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5883 - accuracy: 0.7132 - auc: 0.7710\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5818 - accuracy: 0.7188 - auc: 0.7770\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5792 - accuracy: 0.7226 - auc: 0.7790\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5596 - accuracy: 0.7409 - auc: 0.8026\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5732 - accuracy: 0.7237 - auc: 0.7846\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5533 - accuracy: 0.7436 - auc: 0.8066\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.5529 - accuracy: 0.7444 - auc: 0.8075\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.5542 - accuracy: 0.7376 - auc: 0.8027\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.5448 - accuracy: 0.7504 - auc: 0.8149\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5461 - accuracy: 0.7430 - auc: 0.8120\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5455 - accuracy: 0.7494 - auc: 0.8139\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.5388 - accuracy: 0.7515 - auc: 0.8187\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.5320 - accuracy: 0.7619 - auc: 0.8261\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5329 - accuracy: 0.7595 - auc: 0.8250\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.5360 - accuracy: 0.7586 - auc: 0.8223\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.5330 - accuracy: 0.7565 - auc: 0.8233\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5200 - accuracy: 0.7676 - auc: 0.8362\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5250 - accuracy: 0.7635 - auc: 0.8304\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5150 - accuracy: 0.7740 - auc: 0.8413\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5254 - accuracy: 0.7631 - auc: 0.8296\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5213 - accuracy: 0.7694 - auc: 0.8345\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.5270 - accuracy: 0.7631 - auc: 0.8277\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5260 - accuracy: 0.7579 - auc: 0.8265\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.5169 - accuracy: 0.7736 - auc: 0.8365\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.5127 - accuracy: 0.7720 - auc: 0.8397\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.5238 - accuracy: 0.7619 - auc: 0.8311\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.5087 - accuracy: 0.7774 - auc: 0.8433\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.5059 - accuracy: 0.7751 - auc: 0.8452\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5019 - accuracy: 0.7799 - auc: 0.8488\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5043 - accuracy: 0.7784 - auc: 0.8463\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5120 - accuracy: 0.7699 - auc: 0.8375\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5011 - accuracy: 0.7822 - auc: 0.8495\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5143 - accuracy: 0.7740 - auc: 0.8369\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5116 - accuracy: 0.7667 - auc: 0.8367\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5082 - accuracy: 0.7739 - auc: 0.8401\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4971 - accuracy: 0.7786 - auc: 0.8495\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4948 - accuracy: 0.7821 - auc: 0.8516\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5011 - accuracy: 0.7780 - auc: 0.8462\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4978 - accuracy: 0.7847 - auc: 0.8496\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4950 - accuracy: 0.7835 - auc: 0.8513\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4902 - accuracy: 0.7870 - auc: 0.8557\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5020 - accuracy: 0.7812 - auc: 0.8462\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4891 - accuracy: 0.7870 - auc: 0.8558\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4942 - accuracy: 0.7846 - auc: 0.8513\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4883 - accuracy: 0.7872 - auc: 0.8556\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4832 - accuracy: 0.7935 - auc: 0.8603\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4937 - accuracy: 0.7839 - auc: 0.8523\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4925 - accuracy: 0.7846 - auc: 0.8524\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4844 - accuracy: 0.7912 - auc: 0.8582\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4926 - accuracy: 0.7830 - auc: 0.8511\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4830 - accuracy: 0.7933 - auc: 0.8595\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4800 - accuracy: 0.7935 - auc: 0.8624\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4866 - accuracy: 0.7894 - auc: 0.8564\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4849 - accuracy: 0.7910 - auc: 0.8565\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.4927 - accuracy: 0.7815 - auc: 0.8513\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.5040 - accuracy: 0.7741 - auc: 0.8413\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4859 - accuracy: 0.7881 - auc: 0.8575\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4814 - accuracy: 0.7874 - auc: 0.8594\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4770 - accuracy: 0.7975 - auc: 0.8633\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4809 - accuracy: 0.7949 - auc: 0.8603\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4771 - accuracy: 0.7979 - auc: 0.8628\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4787 - accuracy: 0.7952 - auc: 0.8613\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4894 - accuracy: 0.7862 - auc: 0.8530\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4780 - accuracy: 0.7950 - auc: 0.8624\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4912 - accuracy: 0.7849 - auc: 0.8510\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4769 - accuracy: 0.7930 - auc: 0.8621\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4869 - accuracy: 0.7859 - auc: 0.8540\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.4785 - accuracy: 0.7924 - auc: 0.8607\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 3s 10ms/step - loss: 0.4837 - accuracy: 0.7903 - auc: 0.8564\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.4793 - accuracy: 0.7972 - auc: 0.8607\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4775 - accuracy: 0.7946 - auc: 0.8615\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4843 - accuracy: 0.7880 - auc: 0.8561\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4733 - accuracy: 0.7975 - auc: 0.8643\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4778 - accuracy: 0.7936 - auc: 0.8612\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4763 - accuracy: 0.7912 - auc: 0.8610\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4701 - accuracy: 0.7995 - auc: 0.8664\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4734 - accuracy: 0.7966 - auc: 0.8637\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4750 - accuracy: 0.7962 - auc: 0.8621\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4800 - accuracy: 0.7887 - auc: 0.8590\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4830 - accuracy: 0.7893 - auc: 0.8563\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4722 - accuracy: 0.7994 - auc: 0.8652\n",
            "63/63 [==============================] - 1s 3ms/step - loss: 0.4746 - accuracy: 0.8050 - auc: 0.8654\n",
            "Evaluation results: [0.4745708107948303, 0.8050000071525574, 0.8653606176376343]\n",
            "63/63 [==============================] - 0s 2ms/step\n",
            "ROC AUC score: 0.8653680913784085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Checking if deep neural networks can give more higher results."
      ],
      "metadata": {
        "id": "uZqvMD9nKcVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a deeper neural network\n",
        "hidden_layers = tf.keras.layers.Dense(64, activation = 'relu')(concatenated_inputs)\n",
        "hidden_layers = tf.keras.layers.Dropout(0.5)(hidden_layers)\n",
        "hidden_layers = tf.keras.layers.Dense(32, activation = 'relu')(hidden_layers)\n",
        "hidden_layers = tf.keras.layers.Dropout(0.5)(hidden_layers)\n",
        "hidden_layers = tf.keras.layers.Dense(16, activation = 'relu')(hidden_layers)\n",
        "deep_linear_model = tf.keras.layers.Dense(1, activation = 'sigmoid')(hidden_layers)\n",
        "\n",
        "deep_model = tf.keras.Model(inputs = inputs, outputs = deep_linear_model)\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])"
      ],
      "metadata": {
        "id": "imaCmdg5Kkab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "model.fit(train_ds, epochs = 200)\n",
        "\n",
        "# Evaluation of the model\n",
        "eval_result = model.evaluate(test_ds)\n",
        "print(f\"Evaluation results: {eval_result}\")\n",
        "\n",
        "# Getting predictions and calculate ROC AUC score\n",
        "test_predictions = model.predict(test_ds)\n",
        "true_labels = list(test_df['satisfaction'])\n",
        "roc_auc = roc_auc_score(true_labels, test_predictions)\n",
        "print(f\"ROC AUC score: {roc_auc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-DtCxfPLmOT",
        "outputId": "97395635-5a14-431c-9f89-b6af2b75f2ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "250/250 [==============================] - 2s 4ms/step - loss: 0.4761 - accuracy: 0.7930 - auc: 0.8605\n",
            "Epoch 2/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4751 - accuracy: 0.7970 - auc: 0.8632\n",
            "Epoch 3/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4709 - accuracy: 0.7974 - auc: 0.8654\n",
            "Epoch 4/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4721 - accuracy: 0.7989 - auc: 0.8637\n",
            "Epoch 5/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4755 - accuracy: 0.7940 - auc: 0.8610\n",
            "Epoch 6/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4698 - accuracy: 0.7990 - auc: 0.8665\n",
            "Epoch 7/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4848 - accuracy: 0.7874 - auc: 0.8545\n",
            "Epoch 8/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4679 - accuracy: 0.8030 - auc: 0.8669\n",
            "Epoch 9/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4768 - accuracy: 0.7952 - auc: 0.8602\n",
            "Epoch 10/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4715 - accuracy: 0.7991 - auc: 0.8643\n",
            "Epoch 11/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4657 - accuracy: 0.7985 - auc: 0.8687\n",
            "Epoch 12/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4662 - accuracy: 0.7996 - auc: 0.8682\n",
            "Epoch 13/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4659 - accuracy: 0.7985 - auc: 0.8685\n",
            "Epoch 14/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4734 - accuracy: 0.7961 - auc: 0.8632\n",
            "Epoch 15/200\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.4685 - accuracy: 0.7995 - auc: 0.8665\n",
            "Epoch 16/200\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.4733 - accuracy: 0.7965 - auc: 0.8631\n",
            "Epoch 17/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4704 - accuracy: 0.7962 - auc: 0.8643\n",
            "Epoch 18/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4754 - accuracy: 0.7979 - auc: 0.8614\n",
            "Epoch 19/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4668 - accuracy: 0.8001 - auc: 0.8675\n",
            "Epoch 20/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4671 - accuracy: 0.7971 - auc: 0.8668\n",
            "Epoch 21/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4693 - accuracy: 0.8015 - auc: 0.8659\n",
            "Epoch 22/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4734 - accuracy: 0.7931 - auc: 0.8621\n",
            "Epoch 23/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4895 - accuracy: 0.7854 - auc: 0.8517\n",
            "Epoch 24/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4691 - accuracy: 0.7966 - auc: 0.8653\n",
            "Epoch 25/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4750 - accuracy: 0.7955 - auc: 0.8613\n",
            "Epoch 26/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4686 - accuracy: 0.7976 - auc: 0.8658\n",
            "Epoch 27/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4713 - accuracy: 0.7976 - auc: 0.8639\n",
            "Epoch 28/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4625 - accuracy: 0.8019 - auc: 0.8702\n",
            "Epoch 29/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4583 - accuracy: 0.8056 - auc: 0.8735\n",
            "Epoch 30/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4816 - accuracy: 0.7872 - auc: 0.8563\n",
            "Epoch 31/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4617 - accuracy: 0.8033 - auc: 0.8712\n",
            "Epoch 32/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4666 - accuracy: 0.7959 - auc: 0.8664\n",
            "Epoch 33/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4637 - accuracy: 0.8006 - auc: 0.8691\n",
            "Epoch 34/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4723 - accuracy: 0.7934 - auc: 0.8632\n",
            "Epoch 35/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4720 - accuracy: 0.7939 - auc: 0.8627\n",
            "Epoch 36/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4689 - accuracy: 0.7959 - auc: 0.8652\n",
            "Epoch 37/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4657 - accuracy: 0.8008 - auc: 0.8677\n",
            "Epoch 38/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4665 - accuracy: 0.8035 - auc: 0.8677\n",
            "Epoch 39/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4639 - accuracy: 0.8012 - auc: 0.8689\n",
            "Epoch 40/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4640 - accuracy: 0.8021 - auc: 0.8691\n",
            "Epoch 41/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4610 - accuracy: 0.8056 - auc: 0.8712\n",
            "Epoch 42/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4711 - accuracy: 0.7985 - auc: 0.8644\n",
            "Epoch 43/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4676 - accuracy: 0.7996 - auc: 0.8664\n",
            "Epoch 44/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4633 - accuracy: 0.8033 - auc: 0.8690\n",
            "Epoch 45/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4822 - accuracy: 0.7926 - auc: 0.8574\n",
            "Epoch 46/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4640 - accuracy: 0.8019 - auc: 0.8689\n",
            "Epoch 47/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4651 - accuracy: 0.8009 - auc: 0.8685\n",
            "Epoch 48/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4618 - accuracy: 0.8006 - auc: 0.8701\n",
            "Epoch 49/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4720 - accuracy: 0.7984 - auc: 0.8629\n",
            "Epoch 50/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4570 - accuracy: 0.8040 - auc: 0.8738\n",
            "Epoch 51/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4690 - accuracy: 0.7990 - auc: 0.8652\n",
            "Epoch 52/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4657 - accuracy: 0.7961 - auc: 0.8670\n",
            "Epoch 53/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4652 - accuracy: 0.8018 - auc: 0.8686\n",
            "Epoch 54/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4647 - accuracy: 0.8008 - auc: 0.8685\n",
            "Epoch 55/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4724 - accuracy: 0.7985 - auc: 0.8631\n",
            "Epoch 56/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4639 - accuracy: 0.8009 - auc: 0.8686\n",
            "Epoch 57/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4665 - accuracy: 0.7985 - auc: 0.8668\n",
            "Epoch 58/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4604 - accuracy: 0.8033 - auc: 0.8716\n",
            "Epoch 59/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4606 - accuracy: 0.8035 - auc: 0.8710\n",
            "Epoch 60/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4665 - accuracy: 0.8019 - auc: 0.8675\n",
            "Epoch 61/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4630 - accuracy: 0.8000 - auc: 0.8690\n",
            "Epoch 62/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4650 - accuracy: 0.8014 - auc: 0.8678\n",
            "Epoch 63/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4653 - accuracy: 0.7976 - auc: 0.8679\n",
            "Epoch 64/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4608 - accuracy: 0.8089 - auc: 0.8704\n",
            "Epoch 65/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4721 - accuracy: 0.7990 - auc: 0.8641\n",
            "Epoch 66/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4636 - accuracy: 0.8019 - auc: 0.8689\n",
            "Epoch 67/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4641 - accuracy: 0.8035 - auc: 0.8683\n",
            "Epoch 68/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4647 - accuracy: 0.8049 - auc: 0.8682\n",
            "Epoch 69/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4648 - accuracy: 0.8037 - auc: 0.8686\n",
            "Epoch 70/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4708 - accuracy: 0.8016 - auc: 0.8644\n",
            "Epoch 71/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4655 - accuracy: 0.8035 - auc: 0.8678\n",
            "Epoch 72/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4719 - accuracy: 0.7946 - auc: 0.8634\n",
            "Epoch 73/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4585 - accuracy: 0.8034 - auc: 0.8724\n",
            "Epoch 74/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4636 - accuracy: 0.8034 - auc: 0.8693\n",
            "Epoch 75/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4584 - accuracy: 0.8062 - auc: 0.8720\n",
            "Epoch 76/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4587 - accuracy: 0.8055 - auc: 0.8719\n",
            "Epoch 77/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4629 - accuracy: 0.8048 - auc: 0.8699\n",
            "Epoch 78/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4593 - accuracy: 0.8040 - auc: 0.8716\n",
            "Epoch 79/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4617 - accuracy: 0.8016 - auc: 0.8697\n",
            "Epoch 80/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4707 - accuracy: 0.7983 - auc: 0.8648\n",
            "Epoch 81/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4615 - accuracy: 0.8054 - auc: 0.8702\n",
            "Epoch 82/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4640 - accuracy: 0.8024 - auc: 0.8682\n",
            "Epoch 83/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4621 - accuracy: 0.8023 - auc: 0.8696\n",
            "Epoch 84/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4582 - accuracy: 0.8064 - auc: 0.8725\n",
            "Epoch 85/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4697 - accuracy: 0.7995 - auc: 0.8652\n",
            "Epoch 86/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4619 - accuracy: 0.8012 - auc: 0.8698\n",
            "Epoch 87/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4782 - accuracy: 0.7977 - auc: 0.8606\n",
            "Epoch 88/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4681 - accuracy: 0.8006 - auc: 0.8658\n",
            "Epoch 89/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4612 - accuracy: 0.8020 - auc: 0.8701\n",
            "Epoch 90/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4589 - accuracy: 0.8055 - auc: 0.8728\n",
            "Epoch 91/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4578 - accuracy: 0.8012 - auc: 0.8724\n",
            "Epoch 92/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4748 - accuracy: 0.7979 - auc: 0.8622\n",
            "Epoch 93/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4588 - accuracy: 0.8052 - auc: 0.8721\n",
            "Epoch 94/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4685 - accuracy: 0.7976 - auc: 0.8658\n",
            "Epoch 95/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4624 - accuracy: 0.8039 - auc: 0.8697\n",
            "Epoch 96/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4727 - accuracy: 0.7943 - auc: 0.8630\n",
            "Epoch 97/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4615 - accuracy: 0.8035 - auc: 0.8700\n",
            "Epoch 98/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4543 - accuracy: 0.8081 - auc: 0.8756\n",
            "Epoch 99/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4623 - accuracy: 0.8049 - auc: 0.8699\n",
            "Epoch 100/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4630 - accuracy: 0.8066 - auc: 0.8694\n",
            "Epoch 101/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4860 - accuracy: 0.7893 - auc: 0.8557\n",
            "Epoch 102/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4629 - accuracy: 0.8070 - auc: 0.8691\n",
            "Epoch 103/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4703 - accuracy: 0.7980 - auc: 0.8649\n",
            "Epoch 104/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4653 - accuracy: 0.8002 - auc: 0.8679\n",
            "Epoch 105/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4632 - accuracy: 0.7996 - auc: 0.8687\n",
            "Epoch 106/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4575 - accuracy: 0.8054 - auc: 0.8730\n",
            "Epoch 107/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4599 - accuracy: 0.8062 - auc: 0.8715\n",
            "Epoch 108/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4519 - accuracy: 0.8092 - auc: 0.8766\n",
            "Epoch 109/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4675 - accuracy: 0.8006 - auc: 0.8672\n",
            "Epoch 110/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4633 - accuracy: 0.8040 - auc: 0.8697\n",
            "Epoch 111/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4636 - accuracy: 0.8015 - auc: 0.8687\n",
            "Epoch 112/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4590 - accuracy: 0.8044 - auc: 0.8718\n",
            "Epoch 113/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4645 - accuracy: 0.8020 - auc: 0.8683\n",
            "Epoch 114/200\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.4601 - accuracy: 0.8036 - auc: 0.8710\n",
            "Epoch 115/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4572 - accuracy: 0.8083 - auc: 0.8728\n",
            "Epoch 116/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4613 - accuracy: 0.8039 - auc: 0.8707\n",
            "Epoch 117/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4620 - accuracy: 0.8031 - auc: 0.8697\n",
            "Epoch 118/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4623 - accuracy: 0.7997 - auc: 0.8697\n",
            "Epoch 119/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4665 - accuracy: 0.7970 - auc: 0.8667\n",
            "Epoch 120/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4619 - accuracy: 0.8033 - auc: 0.8703\n",
            "Epoch 121/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4682 - accuracy: 0.8009 - auc: 0.8670\n",
            "Epoch 122/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4683 - accuracy: 0.7985 - auc: 0.8665\n",
            "Epoch 123/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4692 - accuracy: 0.7951 - auc: 0.8652\n",
            "Epoch 124/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4600 - accuracy: 0.8029 - auc: 0.8710\n",
            "Epoch 125/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4658 - accuracy: 0.7999 - auc: 0.8675\n",
            "Epoch 126/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4566 - accuracy: 0.8048 - auc: 0.8732\n",
            "Epoch 127/200\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.4542 - accuracy: 0.8111 - auc: 0.8751\n",
            "Epoch 128/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4625 - accuracy: 0.8041 - auc: 0.8697\n",
            "Epoch 129/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4583 - accuracy: 0.8048 - auc: 0.8719\n",
            "Epoch 130/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4717 - accuracy: 0.7983 - auc: 0.8632\n",
            "Epoch 131/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4632 - accuracy: 0.7996 - auc: 0.8693\n",
            "Epoch 132/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4576 - accuracy: 0.8086 - auc: 0.8732\n",
            "Epoch 133/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4608 - accuracy: 0.7983 - auc: 0.8705\n",
            "Epoch 134/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4665 - accuracy: 0.8025 - auc: 0.8678\n",
            "Epoch 135/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4596 - accuracy: 0.8070 - auc: 0.8715\n",
            "Epoch 136/200\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.4662 - accuracy: 0.8004 - auc: 0.8669\n",
            "Epoch 137/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4740 - accuracy: 0.7944 - auc: 0.8625\n",
            "Epoch 138/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4575 - accuracy: 0.8069 - auc: 0.8727\n",
            "Epoch 139/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4626 - accuracy: 0.7989 - auc: 0.8695\n",
            "Epoch 140/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4614 - accuracy: 0.8050 - auc: 0.8706\n",
            "Epoch 141/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4602 - accuracy: 0.8027 - auc: 0.8712\n",
            "Epoch 142/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4604 - accuracy: 0.8051 - auc: 0.8713\n",
            "Epoch 143/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4641 - accuracy: 0.8030 - auc: 0.8689\n",
            "Epoch 144/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4570 - accuracy: 0.8051 - auc: 0.8728\n",
            "Epoch 145/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4745 - accuracy: 0.7981 - auc: 0.8628\n",
            "Epoch 146/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4666 - accuracy: 0.7968 - auc: 0.8665\n",
            "Epoch 147/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4568 - accuracy: 0.8076 - auc: 0.8734\n",
            "Epoch 148/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4637 - accuracy: 0.8019 - auc: 0.8691\n",
            "Epoch 149/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4711 - accuracy: 0.7986 - auc: 0.8649\n",
            "Epoch 150/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4665 - accuracy: 0.8000 - auc: 0.8671\n",
            "Epoch 151/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4682 - accuracy: 0.7994 - auc: 0.8664\n",
            "Epoch 152/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4576 - accuracy: 0.8094 - auc: 0.8731\n",
            "Epoch 153/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4687 - accuracy: 0.7964 - auc: 0.8662\n",
            "Epoch 154/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4636 - accuracy: 0.8036 - auc: 0.8690\n",
            "Epoch 155/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4543 - accuracy: 0.8056 - auc: 0.8746\n",
            "Epoch 156/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4672 - accuracy: 0.8012 - auc: 0.8669\n",
            "Epoch 157/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4665 - accuracy: 0.8002 - auc: 0.8672\n",
            "Epoch 158/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4611 - accuracy: 0.8045 - auc: 0.8705\n",
            "Epoch 159/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4597 - accuracy: 0.8045 - auc: 0.8715\n",
            "Epoch 160/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4636 - accuracy: 0.8001 - auc: 0.8691\n",
            "Epoch 161/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4603 - accuracy: 0.8073 - auc: 0.8714\n",
            "Epoch 162/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4611 - accuracy: 0.8034 - auc: 0.8705\n",
            "Epoch 163/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4602 - accuracy: 0.8037 - auc: 0.8709\n",
            "Epoch 164/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4608 - accuracy: 0.8039 - auc: 0.8707\n",
            "Epoch 165/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4594 - accuracy: 0.8052 - auc: 0.8713\n",
            "Epoch 166/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4629 - accuracy: 0.8006 - auc: 0.8693\n",
            "Epoch 167/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4572 - accuracy: 0.8055 - auc: 0.8732\n",
            "Epoch 168/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4623 - accuracy: 0.8019 - auc: 0.8698\n",
            "Epoch 169/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4660 - accuracy: 0.8023 - auc: 0.8674\n",
            "Epoch 170/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4688 - accuracy: 0.8006 - auc: 0.8661\n",
            "Epoch 171/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4644 - accuracy: 0.8058 - auc: 0.8688\n",
            "Epoch 172/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4610 - accuracy: 0.8044 - auc: 0.8708\n",
            "Epoch 173/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4610 - accuracy: 0.8035 - auc: 0.8704\n",
            "Epoch 174/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4629 - accuracy: 0.8016 - auc: 0.8693\n",
            "Epoch 175/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4587 - accuracy: 0.8021 - auc: 0.8723\n",
            "Epoch 176/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4689 - accuracy: 0.7984 - auc: 0.8659\n",
            "Epoch 177/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4568 - accuracy: 0.8070 - auc: 0.8733\n",
            "Epoch 178/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4636 - accuracy: 0.8014 - auc: 0.8694\n",
            "Epoch 179/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4633 - accuracy: 0.8033 - auc: 0.8696\n",
            "Epoch 180/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4561 - accuracy: 0.8073 - auc: 0.8740\n",
            "Epoch 181/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4575 - accuracy: 0.8064 - auc: 0.8728\n",
            "Epoch 182/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4639 - accuracy: 0.7993 - auc: 0.8686\n",
            "Epoch 183/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4656 - accuracy: 0.7996 - auc: 0.8677\n",
            "Epoch 184/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4633 - accuracy: 0.8014 - auc: 0.8691\n",
            "Epoch 185/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4623 - accuracy: 0.8020 - auc: 0.8697\n",
            "Epoch 186/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4566 - accuracy: 0.8054 - auc: 0.8735\n",
            "Epoch 187/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4655 - accuracy: 0.8055 - auc: 0.8680\n",
            "Epoch 188/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4631 - accuracy: 0.8019 - auc: 0.8695\n",
            "Epoch 189/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4574 - accuracy: 0.8045 - auc: 0.8731\n",
            "Epoch 190/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4622 - accuracy: 0.8055 - auc: 0.8705\n",
            "Epoch 191/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4710 - accuracy: 0.7969 - auc: 0.8653\n",
            "Epoch 192/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4695 - accuracy: 0.7959 - auc: 0.8653\n",
            "Epoch 193/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4559 - accuracy: 0.8071 - auc: 0.8744\n",
            "Epoch 194/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4618 - accuracy: 0.8061 - auc: 0.8713\n",
            "Epoch 195/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4580 - accuracy: 0.8065 - auc: 0.8730\n",
            "Epoch 196/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.4656 - accuracy: 0.8004 - auc: 0.8680\n",
            "Epoch 197/200\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4674 - accuracy: 0.8012 - auc: 0.8674\n",
            "Epoch 198/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4556 - accuracy: 0.8058 - auc: 0.8737\n",
            "Epoch 199/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4652 - accuracy: 0.7993 - auc: 0.8683\n",
            "Epoch 200/200\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4574 - accuracy: 0.8081 - auc: 0.8733\n",
            "63/63 [==============================] - 1s 3ms/step - loss: 0.5295 - accuracy: 0.7775 - auc: 0.8513\n",
            "Evaluation results: [0.5295398831367493, 0.7774999737739563, 0.8513309955596924]\n",
            "63/63 [==============================] - 0s 2ms/step\n",
            "ROC AUC score: 0.8514060563502852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Making our neural network more deeper and evaluating it's performance on both train and test datasets."
      ],
      "metadata": {
        "id": "xexqIke_OtxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a deeper neural network with batch normalization and regularization\n",
        "hidden_layers_1 = tf.keras.layers.Dense(128, activation = 'relu', kernel_regularizer = tf.keras.regularizers.l2(0.01))(concatenated_inputs)\n",
        "hidden_layers_1 = tf.keras.layers.BatchNormalization()(hidden_layers_1)\n",
        "hidden_layers_1 = tf.keras.layers.Dropout(0.5)(hidden_layers_1)\n",
        "\n",
        "hidden_layers_1 = tf.keras.layers.Dense(64, activation = 'relu', kernel_regularizer = tf.keras.regularizers.l2(0.01))(hidden_layers)\n",
        "hidden_layers_1 = tf.keras.layers.BatchNormalization()(hidden_layers_1)\n",
        "hidden_layers_1 = tf.keras.layers.Dropout(0.5)(hidden_layers_1)\n",
        "\n",
        "hidden_layers_1 = tf.keras.layers.Dense(32, activation = 'relu', kernel_regularizer = tf.keras.regularizers.l2(0.01))(hidden_layers)\n",
        "hidden_layers_1 = tf.keras.layers.BatchNormalization()(hidden_layers_1)\n",
        "hidden_layers_1 = tf.keras.layers.Dropout(0.5)(hidden_layers_1)\n",
        "\n",
        "hidden_layers_1 = tf.keras.layers.Dense(16, activation = 'relu', kernel_regularizer = tf.keras.regularizers.l2(0.01))(hidden_layers)\n",
        "hidden_layers_1 = tf.keras.layers.BatchNormalization()(hidden_layers_1)\n",
        "hidden_layers_1 = tf.keras.layers.Dropout(0.5)(hidden_layers_1)\n",
        "\n",
        "adv_model = tf.keras.layers.Dense(1, activation = 'sigmoid')(hidden_layers_1)\n",
        "\n",
        "# Model\n",
        "advanced_model = tf.keras.Model(inputs = inputs, outputs = adv_model)\n",
        "\n",
        "#Optimizer\n",
        "initial_learning_rate = 0.001\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate, decay_steps = 10000, decay_rate = 0.9, staircase = True\n",
        ")\n",
        "\n",
        "optimizer = tf.keras.optimizers.AdamW(learning_rate = lr_schedule)\n",
        "advanced_model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 100, restore_best_weights = True)\n",
        "\n",
        "\n",
        "# Training the model\n",
        "history = advanced_model.fit(train_ds, validation_data = test_ds, epochs = 200, callbacks = [early_stopping])\n",
        "\n",
        "# Evaluation of the model\n",
        "eval_result = advanced_model.evaluate(test_ds)\n",
        "print(f\"Evaluation results: {eval_result}\")\n",
        "\n",
        "# Getting predictions and calculate ROC AUC score\n",
        "test_predictions = advanced_model.predict(test_ds).flatten()\n",
        "true_labels = test_df['satisfaction'].values\n",
        "roc_auc = roc_auc_score(true_labels, test_predictions)\n",
        "print(f\"ROC AUC score: {roc_auc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbMWi8gnLw7M",
        "outputId": "39d322b0-aca5-408a-c4f2-d9e0010fb46c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "250/250 [==============================] - 4s 6ms/step - loss: 1.0266 - accuracy: 0.4852 - auc: 0.4870 - val_loss: 0.7849 - val_accuracy: 0.6245 - val_auc: 0.6322\n",
            "Epoch 2/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.8383 - accuracy: 0.5369 - auc: 0.5515 - val_loss: 0.7537 - val_accuracy: 0.6255 - val_auc: 0.6337\n",
            "Epoch 3/200\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.7780 - accuracy: 0.5670 - auc: 0.5818 - val_loss: 0.7391 - val_accuracy: 0.5975 - val_auc: 0.6360\n",
            "Epoch 4/200\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.7419 - accuracy: 0.5754 - auc: 0.5998 - val_loss: 0.7242 - val_accuracy: 0.5965 - val_auc: 0.6347\n",
            "Epoch 5/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.7184 - accuracy: 0.5938 - auc: 0.6159 - val_loss: 0.7138 - val_accuracy: 0.5965 - val_auc: 0.6367\n",
            "Epoch 6/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.7054 - accuracy: 0.5950 - auc: 0.6198 - val_loss: 0.7029 - val_accuracy: 0.5990 - val_auc: 0.6354\n",
            "Epoch 7/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6893 - accuracy: 0.6064 - auc: 0.6317 - val_loss: 0.6968 - val_accuracy: 0.5955 - val_auc: 0.6334\n",
            "Epoch 8/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6880 - accuracy: 0.6039 - auc: 0.6286 - val_loss: 0.6938 - val_accuracy: 0.5845 - val_auc: 0.6361\n",
            "Epoch 9/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6765 - accuracy: 0.6115 - auc: 0.6353 - val_loss: 0.6858 - val_accuracy: 0.5970 - val_auc: 0.6347\n",
            "Epoch 10/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6699 - accuracy: 0.6152 - auc: 0.6387 - val_loss: 0.6870 - val_accuracy: 0.5850 - val_auc: 0.6347\n",
            "Epoch 11/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6662 - accuracy: 0.6242 - auc: 0.6436 - val_loss: 0.6837 - val_accuracy: 0.5865 - val_auc: 0.6356\n",
            "Epoch 12/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6678 - accuracy: 0.6180 - auc: 0.6345 - val_loss: 0.6777 - val_accuracy: 0.5980 - val_auc: 0.6355\n",
            "Epoch 13/200\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.6655 - accuracy: 0.6223 - auc: 0.6371 - val_loss: 0.6738 - val_accuracy: 0.6035 - val_auc: 0.6348\n",
            "Epoch 14/200\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.6637 - accuracy: 0.6225 - auc: 0.6418 - val_loss: 0.6700 - val_accuracy: 0.6170 - val_auc: 0.6348\n",
            "Epoch 15/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6626 - accuracy: 0.6160 - auc: 0.6416 - val_loss: 0.6689 - val_accuracy: 0.6180 - val_auc: 0.6347\n",
            "Epoch 16/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6617 - accuracy: 0.6264 - auc: 0.6415 - val_loss: 0.6677 - val_accuracy: 0.6165 - val_auc: 0.6358\n",
            "Epoch 17/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6591 - accuracy: 0.6248 - auc: 0.6472 - val_loss: 0.6693 - val_accuracy: 0.6160 - val_auc: 0.6355\n",
            "Epoch 18/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6592 - accuracy: 0.6242 - auc: 0.6431 - val_loss: 0.6657 - val_accuracy: 0.6225 - val_auc: 0.6363\n",
            "Epoch 19/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6591 - accuracy: 0.6231 - auc: 0.6471 - val_loss: 0.6693 - val_accuracy: 0.6105 - val_auc: 0.6399\n",
            "Epoch 20/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6560 - accuracy: 0.6284 - auc: 0.6503 - val_loss: 0.6679 - val_accuracy: 0.6100 - val_auc: 0.6421\n",
            "Epoch 21/200\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.6540 - accuracy: 0.6277 - auc: 0.6526 - val_loss: 0.6630 - val_accuracy: 0.6255 - val_auc: 0.6458\n",
            "Epoch 22/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6561 - accuracy: 0.6311 - auc: 0.6543 - val_loss: 0.6679 - val_accuracy: 0.6015 - val_auc: 0.6590\n",
            "Epoch 23/200\n",
            "250/250 [==============================] - 2s 8ms/step - loss: 0.6575 - accuracy: 0.6215 - auc: 0.6453 - val_loss: 0.6648 - val_accuracy: 0.6110 - val_auc: 0.6679\n",
            "Epoch 24/200\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.6521 - accuracy: 0.6335 - auc: 0.6615 - val_loss: 0.6623 - val_accuracy: 0.6060 - val_auc: 0.6959\n",
            "Epoch 25/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6502 - accuracy: 0.6321 - auc: 0.6657 - val_loss: 0.6632 - val_accuracy: 0.6040 - val_auc: 0.7383\n",
            "Epoch 26/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6442 - accuracy: 0.6439 - auc: 0.6800 - val_loss: 0.6678 - val_accuracy: 0.5790 - val_auc: 0.7713\n",
            "Epoch 27/200\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.6408 - accuracy: 0.6501 - auc: 0.6856 - val_loss: 0.6694 - val_accuracy: 0.5670 - val_auc: 0.7912\n",
            "Epoch 28/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6363 - accuracy: 0.6535 - auc: 0.6926 - val_loss: 0.6495 - val_accuracy: 0.5935 - val_auc: 0.8084\n",
            "Epoch 29/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6331 - accuracy: 0.6546 - auc: 0.7011 - val_loss: 0.6797 - val_accuracy: 0.5245 - val_auc: 0.8070\n",
            "Epoch 30/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6320 - accuracy: 0.6532 - auc: 0.6989 - val_loss: 0.6496 - val_accuracy: 0.5745 - val_auc: 0.8200\n",
            "Epoch 31/200\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.6297 - accuracy: 0.6530 - auc: 0.7074 - val_loss: 0.6804 - val_accuracy: 0.5290 - val_auc: 0.8195\n",
            "Epoch 32/200\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.6264 - accuracy: 0.6631 - auc: 0.7144 - val_loss: 0.6250 - val_accuracy: 0.6210 - val_auc: 0.8337\n",
            "Epoch 33/200\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.6150 - accuracy: 0.6760 - auc: 0.7274 - val_loss: 0.7040 - val_accuracy: 0.5080 - val_auc: 0.8234\n",
            "Epoch 34/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6174 - accuracy: 0.6712 - auc: 0.7250 - val_loss: 0.6615 - val_accuracy: 0.5395 - val_auc: 0.8190\n",
            "Epoch 35/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6141 - accuracy: 0.6751 - auc: 0.7301 - val_loss: 0.6581 - val_accuracy: 0.5620 - val_auc: 0.8358\n",
            "Epoch 36/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6094 - accuracy: 0.6855 - auc: 0.7371 - val_loss: 0.7286 - val_accuracy: 0.5085 - val_auc: 0.8461\n",
            "Epoch 37/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6058 - accuracy: 0.6898 - auc: 0.7436 - val_loss: 0.7492 - val_accuracy: 0.5085 - val_auc: 0.8319\n",
            "Epoch 38/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.6001 - accuracy: 0.6896 - auc: 0.7507 - val_loss: 0.7167 - val_accuracy: 0.5090 - val_auc: 0.8447\n",
            "Epoch 39/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5961 - accuracy: 0.6936 - auc: 0.7517 - val_loss: 0.7028 - val_accuracy: 0.5195 - val_auc: 0.8535\n",
            "Epoch 40/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5932 - accuracy: 0.6948 - auc: 0.7558 - val_loss: 0.7036 - val_accuracy: 0.5145 - val_auc: 0.8622\n",
            "Epoch 41/200\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.5816 - accuracy: 0.7049 - auc: 0.7676 - val_loss: 0.7562 - val_accuracy: 0.5090 - val_auc: 0.8639\n",
            "Epoch 42/200\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.5792 - accuracy: 0.7140 - auc: 0.7736 - val_loss: 0.8498 - val_accuracy: 0.5085 - val_auc: 0.8697\n",
            "Epoch 43/200\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.5751 - accuracy: 0.7196 - auc: 0.7784 - val_loss: 0.9022 - val_accuracy: 0.5085 - val_auc: 0.8641\n",
            "Epoch 44/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5765 - accuracy: 0.7163 - auc: 0.7752 - val_loss: 0.7979 - val_accuracy: 0.5085 - val_auc: 0.8643\n",
            "Epoch 45/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5759 - accuracy: 0.7100 - auc: 0.7770 - val_loss: 0.9157 - val_accuracy: 0.5085 - val_auc: 0.8490\n",
            "Epoch 46/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5730 - accuracy: 0.7232 - auc: 0.7804 - val_loss: 0.9084 - val_accuracy: 0.5085 - val_auc: 0.8699\n",
            "Epoch 47/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5689 - accuracy: 0.7270 - auc: 0.7840 - val_loss: 0.8216 - val_accuracy: 0.5085 - val_auc: 0.8579\n",
            "Epoch 48/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5587 - accuracy: 0.7340 - auc: 0.7944 - val_loss: 0.8433 - val_accuracy: 0.5085 - val_auc: 0.8706\n",
            "Epoch 49/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5578 - accuracy: 0.7306 - auc: 0.7948 - val_loss: 0.8009 - val_accuracy: 0.5085 - val_auc: 0.8701\n",
            "Epoch 50/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5554 - accuracy: 0.7350 - auc: 0.7971 - val_loss: 0.9197 - val_accuracy: 0.5085 - val_auc: 0.8644\n",
            "Epoch 51/200\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.5660 - accuracy: 0.7296 - auc: 0.7884 - val_loss: 0.8055 - val_accuracy: 0.5085 - val_auc: 0.8686\n",
            "Epoch 52/200\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.5546 - accuracy: 0.7400 - auc: 0.8017 - val_loss: 0.9019 - val_accuracy: 0.5085 - val_auc: 0.8614\n",
            "Epoch 53/200\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.5541 - accuracy: 0.7381 - auc: 0.8003 - val_loss: 0.8319 - val_accuracy: 0.5085 - val_auc: 0.8671\n",
            "Epoch 54/200\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.5578 - accuracy: 0.7269 - auc: 0.7947 - val_loss: 0.8923 - val_accuracy: 0.5085 - val_auc: 0.8708\n",
            "Epoch 55/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5555 - accuracy: 0.7389 - auc: 0.7997 - val_loss: 1.0120 - val_accuracy: 0.5085 - val_auc: 0.8617\n",
            "Epoch 56/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5526 - accuracy: 0.7377 - auc: 0.8014 - val_loss: 0.8731 - val_accuracy: 0.5085 - val_auc: 0.8691\n",
            "Epoch 57/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5473 - accuracy: 0.7406 - auc: 0.8043 - val_loss: 0.9422 - val_accuracy: 0.5085 - val_auc: 0.8695\n",
            "Epoch 58/200\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.5486 - accuracy: 0.7441 - auc: 0.8048 - val_loss: 0.9347 - val_accuracy: 0.5085 - val_auc: 0.8659\n",
            "Epoch 59/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5471 - accuracy: 0.7433 - auc: 0.8068 - val_loss: 0.9600 - val_accuracy: 0.5085 - val_auc: 0.8649\n",
            "Epoch 60/200\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.5443 - accuracy: 0.7458 - auc: 0.8096 - val_loss: 0.7782 - val_accuracy: 0.5125 - val_auc: 0.8601\n",
            "Epoch 61/200\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.5495 - accuracy: 0.7394 - auc: 0.8044 - val_loss: 0.9491 - val_accuracy: 0.5085 - val_auc: 0.8663\n",
            "Epoch 62/200\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.5466 - accuracy: 0.7398 - auc: 0.8055 - val_loss: 0.7909 - val_accuracy: 0.5090 - val_auc: 0.8654\n",
            "Epoch 63/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5371 - accuracy: 0.7471 - auc: 0.8132 - val_loss: 0.8852 - val_accuracy: 0.5085 - val_auc: 0.8640\n",
            "Epoch 64/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5468 - accuracy: 0.7410 - auc: 0.8059 - val_loss: 0.9373 - val_accuracy: 0.5085 - val_auc: 0.8642\n",
            "Epoch 65/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5391 - accuracy: 0.7500 - auc: 0.8119 - val_loss: 0.7991 - val_accuracy: 0.5170 - val_auc: 0.8563\n",
            "Epoch 66/200\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.5359 - accuracy: 0.7511 - auc: 0.8150 - val_loss: 0.9289 - val_accuracy: 0.5085 - val_auc: 0.8629\n",
            "Epoch 67/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5334 - accuracy: 0.7529 - auc: 0.8170 - val_loss: 0.8302 - val_accuracy: 0.5085 - val_auc: 0.8634\n",
            "Epoch 68/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5380 - accuracy: 0.7516 - auc: 0.8141 - val_loss: 0.8626 - val_accuracy: 0.5085 - val_auc: 0.8640\n",
            "Epoch 69/200\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.5424 - accuracy: 0.7496 - auc: 0.8105 - val_loss: 0.8690 - val_accuracy: 0.5085 - val_auc: 0.8654\n",
            "Epoch 70/200\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.5392 - accuracy: 0.7520 - auc: 0.8126 - val_loss: 0.8686 - val_accuracy: 0.5085 - val_auc: 0.8612\n",
            "Epoch 71/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5342 - accuracy: 0.7509 - auc: 0.8164 - val_loss: 0.9286 - val_accuracy: 0.5085 - val_auc: 0.8633\n",
            "Epoch 72/200\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.5364 - accuracy: 0.7564 - auc: 0.8154 - val_loss: 0.9691 - val_accuracy: 0.5085 - val_auc: 0.8655\n",
            "Epoch 73/200\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.5342 - accuracy: 0.7508 - auc: 0.8166 - val_loss: 0.9038 - val_accuracy: 0.5085 - val_auc: 0.8628\n",
            "Epoch 74/200\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.5287 - accuracy: 0.7576 - auc: 0.8221 - val_loss: 0.9801 - val_accuracy: 0.5085 - val_auc: 0.8649\n",
            "Epoch 75/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5248 - accuracy: 0.7590 - auc: 0.8238 - val_loss: 0.9083 - val_accuracy: 0.5085 - val_auc: 0.8620\n",
            "Epoch 76/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5292 - accuracy: 0.7589 - auc: 0.8209 - val_loss: 0.8371 - val_accuracy: 0.5085 - val_auc: 0.8584\n",
            "Epoch 77/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5408 - accuracy: 0.7552 - auc: 0.8139 - val_loss: 0.8022 - val_accuracy: 0.5095 - val_auc: 0.8600\n",
            "Epoch 78/200\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.5281 - accuracy: 0.7576 - auc: 0.8204 - val_loss: 0.8611 - val_accuracy: 0.5085 - val_auc: 0.8638\n",
            "Epoch 79/200\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.5210 - accuracy: 0.7584 - auc: 0.8266 - val_loss: 0.8686 - val_accuracy: 0.5090 - val_auc: 0.8634\n",
            "Epoch 80/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5332 - accuracy: 0.7542 - auc: 0.8166 - val_loss: 0.8330 - val_accuracy: 0.5085 - val_auc: 0.8620\n",
            "Epoch 81/200\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.5303 - accuracy: 0.7596 - auc: 0.8211 - val_loss: 0.8694 - val_accuracy: 0.5085 - val_auc: 0.8622\n",
            "Epoch 82/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5251 - accuracy: 0.7566 - auc: 0.8234 - val_loss: 0.9715 - val_accuracy: 0.5085 - val_auc: 0.8596\n",
            "Epoch 83/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5244 - accuracy: 0.7585 - auc: 0.8239 - val_loss: 0.8734 - val_accuracy: 0.5085 - val_auc: 0.8632\n",
            "Epoch 84/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5260 - accuracy: 0.7574 - auc: 0.8233 - val_loss: 0.9715 - val_accuracy: 0.5085 - val_auc: 0.8607\n",
            "Epoch 85/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5284 - accuracy: 0.7580 - auc: 0.8218 - val_loss: 0.8198 - val_accuracy: 0.5085 - val_auc: 0.8648\n",
            "Epoch 86/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5240 - accuracy: 0.7648 - auc: 0.8245 - val_loss: 0.8615 - val_accuracy: 0.5085 - val_auc: 0.8627\n",
            "Epoch 87/200\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.5206 - accuracy: 0.7645 - auc: 0.8292 - val_loss: 0.8412 - val_accuracy: 0.5085 - val_auc: 0.8606\n",
            "Epoch 88/200\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.5202 - accuracy: 0.7654 - auc: 0.8268 - val_loss: 0.8241 - val_accuracy: 0.5105 - val_auc: 0.8584\n",
            "Epoch 89/200\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.5209 - accuracy: 0.7665 - auc: 0.8262 - val_loss: 0.9002 - val_accuracy: 0.5085 - val_auc: 0.8609\n",
            "Epoch 90/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5241 - accuracy: 0.7580 - auc: 0.8237 - val_loss: 0.9558 - val_accuracy: 0.5085 - val_auc: 0.8615\n",
            "Epoch 91/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5210 - accuracy: 0.7661 - auc: 0.8271 - val_loss: 0.9807 - val_accuracy: 0.5085 - val_auc: 0.8653\n",
            "Epoch 92/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5233 - accuracy: 0.7529 - auc: 0.8231 - val_loss: 0.7884 - val_accuracy: 0.5115 - val_auc: 0.8614\n",
            "Epoch 93/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5259 - accuracy: 0.7640 - auc: 0.8231 - val_loss: 0.8365 - val_accuracy: 0.5085 - val_auc: 0.8637\n",
            "Epoch 94/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5165 - accuracy: 0.7636 - auc: 0.8288 - val_loss: 0.9225 - val_accuracy: 0.5085 - val_auc: 0.8641\n",
            "Epoch 95/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5216 - accuracy: 0.7616 - auc: 0.8261 - val_loss: 0.9471 - val_accuracy: 0.5085 - val_auc: 0.8602\n",
            "Epoch 96/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5209 - accuracy: 0.7595 - auc: 0.8259 - val_loss: 0.9110 - val_accuracy: 0.5085 - val_auc: 0.8635\n",
            "Epoch 97/200\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.5188 - accuracy: 0.7669 - auc: 0.8293 - val_loss: 0.8261 - val_accuracy: 0.5100 - val_auc: 0.8634\n",
            "Epoch 98/200\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.5155 - accuracy: 0.7692 - auc: 0.8310 - val_loss: 0.9160 - val_accuracy: 0.5085 - val_auc: 0.8580\n",
            "Epoch 99/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5173 - accuracy: 0.7695 - auc: 0.8282 - val_loss: 0.7802 - val_accuracy: 0.5280 - val_auc: 0.8489\n",
            "Epoch 100/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5179 - accuracy: 0.7685 - auc: 0.8283 - val_loss: 0.8765 - val_accuracy: 0.5090 - val_auc: 0.8621\n",
            "Epoch 101/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5169 - accuracy: 0.7686 - auc: 0.8312 - val_loss: 0.8706 - val_accuracy: 0.5085 - val_auc: 0.8617\n",
            "Epoch 102/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5231 - accuracy: 0.7617 - auc: 0.8253 - val_loss: 0.8864 - val_accuracy: 0.5085 - val_auc: 0.8626\n",
            "Epoch 103/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5256 - accuracy: 0.7650 - auc: 0.8243 - val_loss: 0.7804 - val_accuracy: 0.5120 - val_auc: 0.8640\n",
            "Epoch 104/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5221 - accuracy: 0.7610 - auc: 0.8259 - val_loss: 0.7744 - val_accuracy: 0.5120 - val_auc: 0.8636\n",
            "Epoch 105/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5170 - accuracy: 0.7692 - auc: 0.8310 - val_loss: 0.7584 - val_accuracy: 0.5185 - val_auc: 0.8649\n",
            "Epoch 106/200\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.5146 - accuracy: 0.7734 - auc: 0.8324 - val_loss: 0.7515 - val_accuracy: 0.5215 - val_auc: 0.8632\n",
            "Epoch 107/200\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.5138 - accuracy: 0.7656 - auc: 0.8311 - val_loss: 0.8782 - val_accuracy: 0.5085 - val_auc: 0.8652\n",
            "Epoch 108/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5198 - accuracy: 0.7646 - auc: 0.8279 - val_loss: 0.7625 - val_accuracy: 0.5210 - val_auc: 0.8639\n",
            "Epoch 109/200\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.5079 - accuracy: 0.7726 - auc: 0.8355 - val_loss: 0.8782 - val_accuracy: 0.5090 - val_auc: 0.8638\n",
            "Epoch 110/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5079 - accuracy: 0.7692 - auc: 0.8363 - val_loss: 0.8819 - val_accuracy: 0.5085 - val_auc: 0.8616\n",
            "Epoch 111/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5187 - accuracy: 0.7656 - auc: 0.8287 - val_loss: 0.7424 - val_accuracy: 0.5285 - val_auc: 0.8593\n",
            "Epoch 112/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5152 - accuracy: 0.7725 - auc: 0.8330 - val_loss: 0.7346 - val_accuracy: 0.5405 - val_auc: 0.8630\n",
            "Epoch 113/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5134 - accuracy: 0.7682 - auc: 0.8317 - val_loss: 0.8240 - val_accuracy: 0.5085 - val_auc: 0.8633\n",
            "Epoch 114/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5131 - accuracy: 0.7682 - auc: 0.8330 - val_loss: 0.8551 - val_accuracy: 0.5085 - val_auc: 0.8612\n",
            "Epoch 115/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5104 - accuracy: 0.7705 - auc: 0.8355 - val_loss: 0.8499 - val_accuracy: 0.5090 - val_auc: 0.8638\n",
            "Epoch 116/200\n",
            "250/250 [==============================] - 1s 6ms/step - loss: 0.5176 - accuracy: 0.7640 - auc: 0.8289 - val_loss: 0.8936 - val_accuracy: 0.5085 - val_auc: 0.8624\n",
            "Epoch 117/200\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.5135 - accuracy: 0.7653 - auc: 0.8319 - val_loss: 0.8342 - val_accuracy: 0.5110 - val_auc: 0.8648\n",
            "Epoch 118/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5114 - accuracy: 0.7704 - auc: 0.8335 - val_loss: 0.7532 - val_accuracy: 0.5230 - val_auc: 0.8619\n",
            "Epoch 119/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5078 - accuracy: 0.7726 - auc: 0.8355 - val_loss: 0.8542 - val_accuracy: 0.5100 - val_auc: 0.8649\n",
            "Epoch 120/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5127 - accuracy: 0.7713 - auc: 0.8338 - val_loss: 0.7742 - val_accuracy: 0.5130 - val_auc: 0.8647\n",
            "Epoch 121/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5209 - accuracy: 0.7675 - auc: 0.8278 - val_loss: 0.7804 - val_accuracy: 0.5115 - val_auc: 0.8661\n",
            "Epoch 122/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5020 - accuracy: 0.7725 - auc: 0.8399 - val_loss: 0.8218 - val_accuracy: 0.5115 - val_auc: 0.8659\n",
            "Epoch 123/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5082 - accuracy: 0.7686 - auc: 0.8365 - val_loss: 0.8361 - val_accuracy: 0.5110 - val_auc: 0.8653\n",
            "Epoch 124/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5090 - accuracy: 0.7691 - auc: 0.8336 - val_loss: 0.8889 - val_accuracy: 0.5090 - val_auc: 0.8654\n",
            "Epoch 125/200\n",
            "250/250 [==============================] - 1s 5ms/step - loss: 0.5004 - accuracy: 0.7765 - auc: 0.8414 - val_loss: 0.8446 - val_accuracy: 0.5090 - val_auc: 0.8668\n",
            "Epoch 126/200\n",
            "250/250 [==============================] - 2s 7ms/step - loss: 0.5048 - accuracy: 0.7717 - auc: 0.8378 - val_loss: 0.8064 - val_accuracy: 0.5110 - val_auc: 0.8674\n",
            "Epoch 127/200\n",
            "250/250 [==============================] - 2s 6ms/step - loss: 0.5066 - accuracy: 0.7742 - auc: 0.8367 - val_loss: 0.7434 - val_accuracy: 0.5265 - val_auc: 0.8658\n",
            "Epoch 128/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5035 - accuracy: 0.7765 - auc: 0.8388 - val_loss: 0.8658 - val_accuracy: 0.5095 - val_auc: 0.8650\n",
            "Epoch 129/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5025 - accuracy: 0.7784 - auc: 0.8402 - val_loss: 0.7487 - val_accuracy: 0.5200 - val_auc: 0.8665\n",
            "Epoch 130/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5033 - accuracy: 0.7771 - auc: 0.8380 - val_loss: 0.8319 - val_accuracy: 0.5115 - val_auc: 0.8666\n",
            "Epoch 131/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5072 - accuracy: 0.7736 - auc: 0.8359 - val_loss: 0.8900 - val_accuracy: 0.5090 - val_auc: 0.8634\n",
            "Epoch 132/200\n",
            "250/250 [==============================] - 1s 4ms/step - loss: 0.5020 - accuracy: 0.7774 - auc: 0.8414 - val_loss: 0.8758 - val_accuracy: 0.5090 - val_auc: 0.8639\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.6210 - auc: 0.8337\n",
            "Evaluation results: [0.6250404119491577, 0.6209999918937683, 0.8337059617042542]\n",
            "63/63 [==============================] - 2s 2ms/step\n",
            "ROC AUC score: 0.8337089418842045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I thought deep neaural networks can solve the problem of classification for prediction of satisfaction of customers from airline service. But it didn't, so I keep working on the models like Random Forest and so on."
      ],
      "metadata": {
        "id": "_4r6hmoS3AeF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Last experimentation goes with Tabular Learner object of fastai library. Here I will try to teach Tabular learner with my dataset and get \"roc_auc\" score. We will see how Tabular Learner object perform in the prediction of satisfaction of customer from airline service.**"
      ],
      "metadata": {
        "id": "MgEdsx3up2ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_cols = ['Age', 'Flight Distance', 'Inflight wifi service', 'Ease of Online booking', 'Food and drink', 'Online boarding', 'Seat comfort', 'Inflight entertainment', 'On-board service', 'Leg room service', 'Baggage handling', 'Checkin service', 'Inflight service', 'Cleanliness']"
      ],
      "metadata": {
        "id": "0_iXT5e7sxbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.dtypes[(train_df.dtypes == 'int64') | (train_df.dtypes == 'float')].index.to_list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdR2G5Nrq49-",
        "outputId": "f63a8679-1197-42cf-ac97-9e536f22b24a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Age',\n",
              " 'Flight Distance',\n",
              " 'Inflight wifi service',\n",
              " 'Ease of Online booking',\n",
              " 'Food and drink',\n",
              " 'Online boarding',\n",
              " 'Seat comfort',\n",
              " 'Inflight entertainment',\n",
              " 'On-board service',\n",
              " 'Leg room service',\n",
              " 'Baggage handling',\n",
              " 'Checkin service',\n",
              " 'Inflight service',\n",
              " 'Cleanliness',\n",
              " 'satisfaction']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "7w6aiLIEqyCF",
        "outputId": "25f4638d-0e47-4247-8814-0c321f2f788c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Customer Type  Age   Type of Travel     Class  Flight Distance  \\\n",
              "2694     Loyal Customer   25  Personal Travel       Eco             1487   \n",
              "5140     Loyal Customer   30  Business travel  Business              501   \n",
              "2568     Loyal Customer   48  Business travel  Business              547   \n",
              "3671  disloyal Customer   38  Business travel       Eco              696   \n",
              "7427     Loyal Customer   64  Personal Travel       Eco             1180   \n",
              "\n",
              "      Inflight wifi service  Ease of Online booking  Food and drink  \\\n",
              "2694                      4                       4               5   \n",
              "5140                      1                       0               2   \n",
              "2568                      1                       2               5   \n",
              "3671                      1                       1               2   \n",
              "7427                      3                       3               2   \n",
              "\n",
              "      Online boarding  Seat comfort  Inflight entertainment  On-board service  \\\n",
              "2694                4             5                       5                 4   \n",
              "5140                0             2                       2                 1   \n",
              "2568                4             4                       5                 5   \n",
              "3671                1             2                       2                 3   \n",
              "7427                3             2                       2                 3   \n",
              "\n",
              "      Leg room service  Baggage handling  Checkin service  Inflight service  \\\n",
              "2694                 5                 5                4                 5   \n",
              "5140                 3                 1                2                 2   \n",
              "2568                 5                 5                5                 5   \n",
              "3671                 1                 4                3                 3   \n",
              "7427                 2                 5                4                 5   \n",
              "\n",
              "      Cleanliness  satisfaction  \n",
              "2694            5             1  \n",
              "5140            2             0  \n",
              "2568            5             1  \n",
              "3671            2             0  \n",
              "7427            2             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc263d4b-252b-4ed9-8bf6-f49143cf4bfe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Customer Type</th>\n",
              "      <th>Age</th>\n",
              "      <th>Type of Travel</th>\n",
              "      <th>Class</th>\n",
              "      <th>Flight Distance</th>\n",
              "      <th>Inflight wifi service</th>\n",
              "      <th>Ease of Online booking</th>\n",
              "      <th>Food and drink</th>\n",
              "      <th>Online boarding</th>\n",
              "      <th>Seat comfort</th>\n",
              "      <th>Inflight entertainment</th>\n",
              "      <th>On-board service</th>\n",
              "      <th>Leg room service</th>\n",
              "      <th>Baggage handling</th>\n",
              "      <th>Checkin service</th>\n",
              "      <th>Inflight service</th>\n",
              "      <th>Cleanliness</th>\n",
              "      <th>satisfaction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2694</th>\n",
              "      <td>Loyal Customer</td>\n",
              "      <td>25</td>\n",
              "      <td>Personal Travel</td>\n",
              "      <td>Eco</td>\n",
              "      <td>1487</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5140</th>\n",
              "      <td>Loyal Customer</td>\n",
              "      <td>30</td>\n",
              "      <td>Business travel</td>\n",
              "      <td>Business</td>\n",
              "      <td>501</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2568</th>\n",
              "      <td>Loyal Customer</td>\n",
              "      <td>48</td>\n",
              "      <td>Business travel</td>\n",
              "      <td>Business</td>\n",
              "      <td>547</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3671</th>\n",
              "      <td>disloyal Customer</td>\n",
              "      <td>38</td>\n",
              "      <td>Business travel</td>\n",
              "      <td>Eco</td>\n",
              "      <td>696</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7427</th>\n",
              "      <td>Loyal Customer</td>\n",
              "      <td>64</td>\n",
              "      <td>Personal Travel</td>\n",
              "      <td>Eco</td>\n",
              "      <td>1180</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc263d4b-252b-4ed9-8bf6-f49143cf4bfe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fc263d4b-252b-4ed9-8bf6-f49143cf4bfe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fc263d4b-252b-4ed9-8bf6-f49143cf4bfe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-994b919f-ace1-4ad4-ab5f-26d2867e7175\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-994b919f-ace1-4ad4-ab5f-26d2867e7175')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-994b919f-ace1-4ad4-ab5f-26d2867e7175 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 8000,\n  \"fields\": [\n    {\n      \"column\": \"Customer Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"disloyal Customer\",\n          \"Loyal Customer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 7,\n        \"max\": 80,\n        \"num_unique_values\": 74,\n        \"samples\": [\n          64,\n          67\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Type of Travel\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Business travel\",\n          \"Personal Travel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Class\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Eco\",\n          \"Business\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Flight Distance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1021,\n        \"min\": 31,\n        \"max\": 4983,\n        \"num_unique_values\": 2213,\n        \"samples\": [\n          3540,\n          2277\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Inflight wifi service\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ease of Online booking\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Food and drink\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          5,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Online boarding\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Seat comfort\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          5,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Inflight entertainment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"On-board service\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Leg room service\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Baggage handling\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Checkin service\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Inflight service\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cleanliness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          5,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"satisfaction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['satisfaction']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X8Mv8-_r7Sk",
        "outputId": "3d853f47-9054-4f5f-bb2c-abd52f3dcc81"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2694    1\n",
              "5140    0\n",
              "2568    1\n",
              "3671    0\n",
              "7427    0\n",
              "       ..\n",
              "2895    0\n",
              "7813    0\n",
              "905     1\n",
              "5192    1\n",
              "235     1\n",
              "Name: satisfaction, Length: 8000, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fastai.callback.core import Callback\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "#Metrics\n",
        "class RocAucCallback(Callback):\n",
        "    def __init__(self):\n",
        "        self.outputs = []\n",
        "        self.targets = []\n",
        "\n",
        "    def before_epoch(self):\n",
        "        self.outputs = []\n",
        "        self.targets = []\n",
        "\n",
        "    def after_batch(self):\n",
        "        self.outputs.append(self.pred)\n",
        "        self.targets.append(self.y)\n",
        "\n",
        "    def after_epoch(self):\n",
        "        outputs = torch.cat(self.outputs).detach().cpu().numpy()\n",
        "        targets = torch.cat(self.targets).detach().cpu().numpy()\n",
        "        roc_auc = roc_auc_score(targets, outputs)\n",
        "        print(f'Epoch {self.epoch}: ROC AUC = {roc_auc:.4f}')\n",
        "\n",
        "        if self.epoch == self.learn.epoch:\n",
        "            self.learn.roc_outputs = outputs\n",
        "            self.learn.roc_targets = targets\n",
        "\n",
        "\n",
        "\n",
        "numerical_cols = ['Age', 'Flight Distance', 'Inflight wifi service', 'Ease of Online booking', 'Food and drink', 'Online boarding', 'Seat comfort', 'Inflight entertainment', 'On-board service', 'Leg room service', 'Baggage handling', 'Checkin service', 'Inflight service', 'Cleanliness']\n",
        "#Tabular Learner object from Fastai library\n",
        "dls = TabularDataLoaders.from_df(df = train_df, bs = 16, y_names = 'satisfaction', skipinitialspace = False, cat_names = train_df.dtypes[train_df.dtypes == 'object'].index.to_list(), cont_names = numerical_cols, procs = [Categorify, Normalize])\n",
        "learn = tabular_learner(dls = dls)\n",
        "learn.fit_one_cycle(100, cbs=RocAucCallback())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "al4a7QJpqTRQ",
        "outputId": "ed9a0950-1ef5-4498-e521-064fe316c329"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.480644</td>\n",
              "      <td>0.417993</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.328892</td>\n",
              "      <td>0.288940</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.205305</td>\n",
              "      <td>0.175915</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.134450</td>\n",
              "      <td>0.114838</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.127561</td>\n",
              "      <td>0.108764</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.124777</td>\n",
              "      <td>0.094754</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.109781</td>\n",
              "      <td>0.083837</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.096540</td>\n",
              "      <td>0.080118</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.092153</td>\n",
              "      <td>0.076177</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.080658</td>\n",
              "      <td>0.069930</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.085458</td>\n",
              "      <td>0.069361</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.085643</td>\n",
              "      <td>0.070709</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.077784</td>\n",
              "      <td>0.067677</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.078083</td>\n",
              "      <td>0.065151</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.086442</td>\n",
              "      <td>0.064414</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.077285</td>\n",
              "      <td>0.066174</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.084427</td>\n",
              "      <td>0.066929</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.071454</td>\n",
              "      <td>0.062442</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.073536</td>\n",
              "      <td>0.065853</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.077578</td>\n",
              "      <td>0.061439</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.081965</td>\n",
              "      <td>0.062475</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.078758</td>\n",
              "      <td>0.055949</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.070520</td>\n",
              "      <td>0.057724</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.072285</td>\n",
              "      <td>0.059290</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.070782</td>\n",
              "      <td>0.057766</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.065035</td>\n",
              "      <td>0.059328</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.069641</td>\n",
              "      <td>0.059303</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.070199</td>\n",
              "      <td>0.057356</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.066465</td>\n",
              "      <td>0.061067</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.063143</td>\n",
              "      <td>0.056025</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.067603</td>\n",
              "      <td>0.055482</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.061562</td>\n",
              "      <td>0.057023</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.061388</td>\n",
              "      <td>0.058016</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.058294</td>\n",
              "      <td>0.054395</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.064277</td>\n",
              "      <td>0.059496</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.062557</td>\n",
              "      <td>0.054899</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.068143</td>\n",
              "      <td>0.057996</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.054307</td>\n",
              "      <td>0.055423</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.062186</td>\n",
              "      <td>0.054421</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.061083</td>\n",
              "      <td>0.052602</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.056531</td>\n",
              "      <td>0.056714</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.059482</td>\n",
              "      <td>0.056231</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.058227</td>\n",
              "      <td>0.053401</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.057198</td>\n",
              "      <td>0.055786</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.057689</td>\n",
              "      <td>0.056409</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.055611</td>\n",
              "      <td>0.056589</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.069042</td>\n",
              "      <td>0.054028</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.055042</td>\n",
              "      <td>0.052340</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.066038</td>\n",
              "      <td>0.054093</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.054087</td>\n",
              "      <td>0.054853</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.054431</td>\n",
              "      <td>0.054242</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.053209</td>\n",
              "      <td>0.051885</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.059087</td>\n",
              "      <td>0.051301</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.050099</td>\n",
              "      <td>0.052920</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.054072</td>\n",
              "      <td>0.050395</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.049276</td>\n",
              "      <td>0.054245</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.056133</td>\n",
              "      <td>0.053412</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.052439</td>\n",
              "      <td>0.052751</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.056269</td>\n",
              "      <td>0.054604</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.054100</td>\n",
              "      <td>0.049692</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.052739</td>\n",
              "      <td>0.059097</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>0.054332</td>\n",
              "      <td>0.054396</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>0.055620</td>\n",
              "      <td>0.052833</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>0.055466</td>\n",
              "      <td>0.056368</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>0.053692</td>\n",
              "      <td>0.051206</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.050932</td>\n",
              "      <td>0.052329</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>0.045185</td>\n",
              "      <td>0.052977</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>0.048706</td>\n",
              "      <td>0.053136</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>0.052815</td>\n",
              "      <td>0.051659</td>\n",
              "      <td>00:08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>0.053386</td>\n",
              "      <td>0.049514</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.048242</td>\n",
              "      <td>0.052589</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>0.051049</td>\n",
              "      <td>0.051938</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.051937</td>\n",
              "      <td>0.053914</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>0.053740</td>\n",
              "      <td>0.048693</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>0.049589</td>\n",
              "      <td>0.050300</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.053672</td>\n",
              "      <td>0.055859</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>0.049968</td>\n",
              "      <td>0.052439</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>0.052745</td>\n",
              "      <td>0.052894</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>0.051079</td>\n",
              "      <td>0.053033</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>0.055087</td>\n",
              "      <td>0.051731</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.050082</td>\n",
              "      <td>0.051362</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>0.050482</td>\n",
              "      <td>0.052521</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>0.049108</td>\n",
              "      <td>0.052249</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>0.046271</td>\n",
              "      <td>0.049928</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>0.045360</td>\n",
              "      <td>0.050268</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.048832</td>\n",
              "      <td>0.050220</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>0.053531</td>\n",
              "      <td>0.052758</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>0.050568</td>\n",
              "      <td>0.050126</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>0.053033</td>\n",
              "      <td>0.051624</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>0.048156</td>\n",
              "      <td>0.050751</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.048204</td>\n",
              "      <td>0.052760</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>0.042097</td>\n",
              "      <td>0.049866</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>0.041530</td>\n",
              "      <td>0.049603</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>0.044032</td>\n",
              "      <td>0.049935</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>0.049079</td>\n",
              "      <td>0.052075</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.042954</td>\n",
              "      <td>0.049210</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.047666</td>\n",
              "      <td>0.050141</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>0.050356</td>\n",
              "      <td>0.052054</td>\n",
              "      <td>00:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>0.042558</td>\n",
              "      <td>0.050820</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.046500</td>\n",
              "      <td>0.054132</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: ROC AUC = 0.7920\n",
            "Epoch 1: ROC AUC = 0.8717\n",
            "Epoch 2: ROC AUC = 0.8880\n",
            "Epoch 3: ROC AUC = 0.9089\n",
            "Epoch 4: ROC AUC = 0.9257\n",
            "Epoch 5: ROC AUC = 0.9334\n",
            "Epoch 6: ROC AUC = 0.9436\n",
            "Epoch 7: ROC AUC = 0.9550\n",
            "Epoch 8: ROC AUC = 0.9581\n",
            "Epoch 9: ROC AUC = 0.9609\n",
            "Epoch 10: ROC AUC = 0.9650\n",
            "Epoch 11: ROC AUC = 0.9648\n",
            "Epoch 12: ROC AUC = 0.9676\n",
            "Epoch 13: ROC AUC = 0.9669\n",
            "Epoch 14: ROC AUC = 0.9651\n",
            "Epoch 15: ROC AUC = 0.9671\n",
            "Epoch 16: ROC AUC = 0.9655\n",
            "Epoch 17: ROC AUC = 0.9713\n",
            "Epoch 18: ROC AUC = 0.9710\n",
            "Epoch 19: ROC AUC = 0.9683\n",
            "Epoch 20: ROC AUC = 0.9682\n",
            "Epoch 21: ROC AUC = 0.9728\n",
            "Epoch 22: ROC AUC = 0.9725\n",
            "Epoch 23: ROC AUC = 0.9745\n",
            "Epoch 24: ROC AUC = 0.9732\n",
            "Epoch 25: ROC AUC = 0.9739\n",
            "Epoch 26: ROC AUC = 0.9745\n",
            "Epoch 27: ROC AUC = 0.9767\n",
            "Epoch 28: ROC AUC = 0.9744\n",
            "Epoch 29: ROC AUC = 0.9753\n",
            "Epoch 30: ROC AUC = 0.9752\n",
            "Epoch 31: ROC AUC = 0.9761\n",
            "Epoch 32: ROC AUC = 0.9783\n",
            "Epoch 33: ROC AUC = 0.9774\n",
            "Epoch 34: ROC AUC = 0.9795\n",
            "Epoch 35: ROC AUC = 0.9781\n",
            "Epoch 36: ROC AUC = 0.9779\n",
            "Epoch 37: ROC AUC = 0.9794\n",
            "Epoch 38: ROC AUC = 0.9811\n",
            "Epoch 39: ROC AUC = 0.9791\n",
            "Epoch 40: ROC AUC = 0.9803\n",
            "Epoch 41: ROC AUC = 0.9805\n",
            "Epoch 42: ROC AUC = 0.9802\n",
            "Epoch 43: ROC AUC = 0.9794\n",
            "Epoch 44: ROC AUC = 0.9815\n",
            "Epoch 45: ROC AUC = 0.9812\n",
            "Epoch 46: ROC AUC = 0.9779\n",
            "Epoch 47: ROC AUC = 0.9815\n",
            "Epoch 48: ROC AUC = 0.9809\n",
            "Epoch 49: ROC AUC = 0.9840\n",
            "Epoch 50: ROC AUC = 0.9821\n",
            "Epoch 51: ROC AUC = 0.9827\n",
            "Epoch 52: ROC AUC = 0.9828\n",
            "Epoch 53: ROC AUC = 0.9842\n",
            "Epoch 54: ROC AUC = 0.9854\n",
            "Epoch 55: ROC AUC = 0.9848\n",
            "Epoch 56: ROC AUC = 0.9841\n",
            "Epoch 57: ROC AUC = 0.9837\n",
            "Epoch 58: ROC AUC = 0.9823\n",
            "Epoch 59: ROC AUC = 0.9848\n",
            "Epoch 60: ROC AUC = 0.9859\n",
            "Epoch 61: ROC AUC = 0.9834\n",
            "Epoch 62: ROC AUC = 0.9858\n",
            "Epoch 63: ROC AUC = 0.9831\n",
            "Epoch 64: ROC AUC = 0.9849\n",
            "Epoch 65: ROC AUC = 0.9849\n",
            "Epoch 66: ROC AUC = 0.9883\n",
            "Epoch 67: ROC AUC = 0.9854\n",
            "Epoch 68: ROC AUC = 0.9848\n",
            "Epoch 69: ROC AUC = 0.9863\n",
            "Epoch 70: ROC AUC = 0.9856\n",
            "Epoch 71: ROC AUC = 0.9868\n",
            "Epoch 72: ROC AUC = 0.9856\n",
            "Epoch 73: ROC AUC = 0.9870\n",
            "Epoch 74: ROC AUC = 0.9876\n",
            "Epoch 75: ROC AUC = 0.9883\n",
            "Epoch 76: ROC AUC = 0.9848\n",
            "Epoch 77: ROC AUC = 0.9869\n",
            "Epoch 78: ROC AUC = 0.9865\n",
            "Epoch 79: ROC AUC = 0.9877\n",
            "Epoch 80: ROC AUC = 0.9872\n",
            "Epoch 81: ROC AUC = 0.9874\n",
            "Epoch 82: ROC AUC = 0.9856\n",
            "Epoch 83: ROC AUC = 0.9894\n",
            "Epoch 84: ROC AUC = 0.9871\n",
            "Epoch 85: ROC AUC = 0.9887\n",
            "Epoch 86: ROC AUC = 0.9869\n",
            "Epoch 87: ROC AUC = 0.9880\n",
            "Epoch 88: ROC AUC = 0.9872\n",
            "Epoch 89: ROC AUC = 0.9881\n",
            "Epoch 90: ROC AUC = 0.9886\n",
            "Epoch 91: ROC AUC = 0.9894\n",
            "Epoch 92: ROC AUC = 0.9897\n",
            "Epoch 93: ROC AUC = 0.9880\n",
            "Epoch 94: ROC AUC = 0.9886\n",
            "Epoch 95: ROC AUC = 0.9901\n",
            "Epoch 96: ROC AUC = 0.9878\n",
            "Epoch 97: ROC AUC = 0.9859\n",
            "Epoch 98: ROC AUC = 0.9893\n",
            "Epoch 99: ROC AUC = 0.9878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Making prediction using learn object then calculating roc_auc score for test dataset\n",
        "preds, targs = learn.get_preds(dl = learn.dls.test_dl(test_df))\n",
        "roc_auc = roc_auc_score(targs, preds)\n",
        "print(f\"ROC AUC score of Tabular learner : {roc_auc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "mJgf14Pv1rZv",
        "outputId": "06ed9728-2720-4d44-acf5-dbc120183fb8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROC AUC score of Tabular learner : 0.9864150739563734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the ROC AUC curve\n",
        "fpr_train, tpr_train, _ = roc_curve(learn.roc_targets, learn.roc_outputs)\n",
        "fpr_test, tpr_test, _ = roc_curve(targs, preds)\n",
        "\n",
        "# Plot the ROC AUC curve\n",
        "plt.figure()\n",
        "plt.plot(fpr_train, tpr_train, color='blue', lw=2, label = f'ROC curve for train set(area = {roc_auc_score(learn.roc_targets, learn.roc_outputs):.2f})')\n",
        "plt.plot(fpr_test, tpr_test, color='red', lw=2, label = f'ROC curve for test set(area = {roc_auc_score(targs, preds):.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve of Tabular Learner(Fastai)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "g4yp3V4_6Hbs",
        "outputId": "edc4ab5d-4209-4c09-bfc2-11c47cf47c7b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**That was amazing score I have ever get, but I have already make pipeline for other machine learning model which is CatBoostClassifier. That is why, I am going to keep this model just in my inventory.**"
      ],
      "metadata": {
        "id": "rpw6a5BN-yx9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YUn0sHLA7aAp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}